<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Machine Learning,notes,校内公开课,Deep Learning," />










<meta name="description" content="从校内深度学习公开课开始，每天高效地学习与记录吧！">
<meta property="og:type" content="article">
<meta property="og:title" content="machine learning">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;03&#x2F;11&#x2F;machine-learning&#x2F;index.html">
<meta property="og:site_name" content="Jingge&#39;s blog">
<meta property="og:description" content="从校内深度学习公开课开始，每天高效地学习与记录吧！">
<meta property="og:image" content="https:&#x2F;&#x2F;github.com&#x2F;jinggew&#x2F;jinggew.github.io&#x2F;blob&#x2F;source&#x2F;_posts&#x2F;machine-learning&#x2F;image-20200311220116042.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;03&#x2F;11&#x2F;machine-learning&#x2F;image-20200311220706311.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311235135688.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;03&#x2F;11&#x2F;machine-learning&#x2F;image-20200311230016827.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;03&#x2F;11&#x2F;machine-learning&#x2F;image-20200311230223713.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;03&#x2F;11&#x2F;machine-learning&#x2F;image-20200311231046782.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311231800367.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311232358886.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315124102183.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315152359157.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315170503707.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311233310919.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311233529287.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315153117623.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311234028935.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311234413017.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311234550862.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311234952926.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311235338823.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200311235453094.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;03&#x2F;11&#x2F;machine-learning&#x2F;image-20200314221135319.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200314221441453.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200314222934879.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315001105621.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315001821550.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315002509926.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315153431413.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200506225343868.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320215713091.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320215733947.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315154348372.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320215747045.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315170950123.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315172804385.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315172826434.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315173021691.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315173912106.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315174131184.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315174634501.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315175029456.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315175337003.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315175604850.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315175928409.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315180026584.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315181922400.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315182714055.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315183542054.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315184356960.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315185247405.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322104900689.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322105002893.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322105002893.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315185505330.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322120820070.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322120957388.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322121601311.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322121717842.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322115807275.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322113443092.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322120703777.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322122240085.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200322122412734.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200315185933145.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200316143951330.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200316144129313.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200316151139272.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200316151923849.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200316153519517.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200316153557151.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200318002036999.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200318002500870.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200318003057057.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319105408387.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319110624279.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319111254790.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319140436418.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319150424650.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319151350569.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200319151806867.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320151950770.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320152154321.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320175245513.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320173846279.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320174015059.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320175652483.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320180203873.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320214219283.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320231845267.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320233013119.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320233148058.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320233351548.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320233454513.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320233853598.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320234827518.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200320235105330.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321213626408.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321213922907.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321224018669.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321225255153.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321225429192.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321225828040.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200321225938539.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404174221618.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404174628820.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404175850464.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404180316145.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404180529609.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404180918667.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404181101851.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404203638226.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404204009462.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404205424868.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200404210031103.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426121216570.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409003136442.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409003737584.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409145623447.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426121346801.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409150831659.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409151024069.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409151333377.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409153544435.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409154752399.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409161341587.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426125632381.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409204750437.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409204836174.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409205108861.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200409205201873.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426131439768.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426145052559.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426145920421.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426150616702.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426151206475.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426151320074.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426153717579.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426153954178.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426154425125.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426154606077.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426154907835.png">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;image-20200426155100505.png">
<meta property="article:published_time" content="2020-03-11T12:37:29.000Z">
<meta property="article:modified_time" content="2020-05-07T08:08:09.115Z">
<meta property="article:author" content="Jingge">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="notes">
<meta property="article:tag" content="校内公开课">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;github.com&#x2F;jinggew&#x2F;jinggew.github.io&#x2F;blob&#x2F;source&#x2F;_posts&#x2F;machine-learning&#x2F;image-20200311220116042.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/03/11/machine-learning/"/>





  <title>machine learning | Jingge's blog</title>
  








<meta name="generator" content="Hexo 4.1.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jingge's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/11/machine-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jingge">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jingge's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">machine learning</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-11T20:37:29+08:00">
                2020-03-11
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2020-05-07T16:08:09+08:00">
                2020-05-07
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>从校内深度学习公开课开始，每天高效地学习与记录吧！</p>
<a id="more"></a> 
<p><strong>目录</strong></p>
<p>[TOC]</p>
<h1 id="校内深度学习公开课"><a href="#校内深度学习公开课" class="headerlink" title="校内深度学习公开课"></a>校内深度学习公开课</h1><h2 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h2><p> <img src="https://github.com/jinggew/jinggew.github.io/blob/source/_posts/machine-learning/image-20200311220116042.png" alt=""> </p>
<p><img src="image-20200311220706311.png" style="zoom:50%;" /></p>
<p><img src="/image-20200311235135688.png" alt="image-20200311235135688" style="zoom:50%;" /></p>
<p><img src="image-20200311230016827.png" style="zoom:50%;" /></p>
<ul>
<li>深度学习的end-to-end：representer和learner可以端到端地学习，见下图。<ul>
<li>但是也不是说只能端到端，Hinton最早的unsupervised pre-training其实是两阶段的；</li>
<li>一些representing learning的算法，效果不一定比深度方法差，端到端可能不一定要做，但是深度学习的常见端到端。</li>
</ul>
</li>
</ul>
<p><img src="image-20200311230223713.png" style="zoom:50%;" /></p>
<h3 id="正则项-惩罚项"><a href="#正则项-惩罚项" class="headerlink" title="正则项/惩罚项"></a>正则项/惩罚项</h3><ul>
<li>度量假设空间的大小，高次多项式空间比线性空间大；</li>
<li>控制模型复杂度。因为机器学习的模型的泛化误差要求，在足够小（简单）的模型上足够大的训练集上训练得到足够小的训练误差，这样的模型才可能是在未知测试数据上效果好（泛化误差小）的模型。</li>
</ul>
<p><img src="image-20200311231046782.png" style="zoom:50%;" /></p>
<h3 id="loss-function损失函数"><a href="#loss-function损失函数" class="headerlink" title="loss function损失函数"></a>loss function损失函数</h3><ul>
<li><p>0-1损失函数和分类准确率是完全对应的，也即和学习出来模型的评价准则对应；</p>
<ul>
<li><blockquote>
<p>评价准则：查准率，查全率，ROC等，直接针对它们优化是很困难的。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>hinge loss, logistic loss不对应，针对它们的优化和最终用来评价模型的准则并不等价。</p>
</li>
</ul>
<h3 id="三种regression"><a href="#三种regression" class="headerlink" title="三种regression"></a>三种regression</h3><h4 id="linear-regression线性回归"><a href="#linear-regression线性回归" class="headerlink" title="linear regression线性回归"></a>linear regression线性回归</h4><p><img src="/image-20200311231800367.png" alt="image-20200311231800367" style="zoom:50%;" /></p>
<ul>
<li><strong>L2损失函数（均方误差）</strong>；</li>
<li>线性假设空间；</li>
<li>L2二范数正则项；</li>
<li>目标函数有闭式解（正规方程normal equation），但是一般闭式解意味着大规模的计算量，这是我们不期望的。</li>
</ul>
<h4 id="logistic-regression逻辑回归"><a href="#logistic-regression逻辑回归" class="headerlink" title="logistic regression逻辑回归"></a>logistic regression逻辑回归</h4><p><img src="/image-20200311232358886.png" alt="image-20200311232358886" style="zoom:50%;" /></p>
<ul>
<li><p>回归（预测）模型采用sigmoid函数，即（个人理解：也是相当于把预测值映射成0到1的概率范围内，和符号函数比是非线性映射）</p>
<script type="math/tex; mode=display">
f(x_i)=sigmoid(\theta ^T x_i)=\frac{1}{1+e^{-\theta ^T x_i}}\notag</script><p><img src="/image-20200315124102183.png" alt="image-20200315124102183" style="zoom:50%;" /></p>
</li>
<li><p><strong>logistic损失函数</strong>，交叉熵损失函数，让越远离实际y值的损失值越大，越接近实际y值的损失值越接近于0：</p>
<script type="math/tex; mode=display">
\begin{align}
L(y_i,f(x_i);\theta)&=
\begin{cases} 
-\mathrm{log}f(x_i), & \text {if $y_i=1$ } \notag\\ 
-\mathrm{log}(1-f(x_i)), & \text{if $y_i=0$} \\
\end{cases} \notag\\
&= -y_i \mathrm{log}f(x_i) -(1-y_i)\mathrm{log}(1-f(x_i)) \notag
\end{align}
\notag</script><p>或者从似然函数的角度看，似然函数最大化转换成损失函数最小化，加负号即可：</p>
<p><img src="/image-20200315152359157.png" alt="image-20200315152359157" style="zoom:50%;" /></p>
<blockquote>
<p>补充：交叉熵和信息论</p>
<p><img src="/image-20200315170503707.png" alt="image-20200315170503707" style="zoom:50%;" /></p>
</blockquote>
</li>
<li><p>不能求闭式解，用梯度下降法迭代求解。</p>
</li>
</ul>
<h4 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h4><p><img src="/image-20200311233310919.png" alt="image-20200311233310919" style="zoom:50%;" /></p>
<ul>
<li><p>logistic 回归在<strong>多分类</strong>问题上的推广；</p>
</li>
<li><p><strong>softmax function：回归处理</strong>，将输出每个类别的score变成probability；</p>
<p><img src="/image-20200311233529287.png" alt="image-20200311233529287" style="zoom:50%;" /></p>
</li>
<li><p><strong>交叉熵cross entropy损失函数</strong>：预测概率向量和标签（概率）向量的距离。</p>
<p><img src="/image-20200315153117623.png" alt="image-20200315153117623" style="zoom:50%;" /></p>
</li>
</ul>
<h3 id="误差"><a href="#误差" class="headerlink" title="误差"></a>误差</h3><p><img src="/image-20200311234028935.png" alt="image-20200311234028935" style="zoom: 50%;" /></p>
<ul>
<li><p>近似误差：假设空间好不好，近似误差太大可能就需要换一个假设空间更大的模型；</p>
</li>
<li><p>估计误差：估计误差大则说明假设空间可能太大了，否则学习算法在太大的假设空间中可能找不到最优的假设。</p>
<ul>
<li><blockquote>
<p>深度学习就是要学习feature extraction让假设空间和真实目标函数之间的gap变小。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="参数化与非参数化"><a href="#参数化与非参数化" class="headerlink" title="参数化与非参数化"></a>参数化与非参数化</h3><p><img src="/image-20200311234413017.png" alt="image-20200311234413017" style="zoom:50%;" /></p>
<h3 id="维度灾难与流形学习"><a href="#维度灾难与流形学习" class="headerlink" title="维度灾难与流形学习"></a>维度灾难与流形学习</h3><p><img src="/image-20200311234550862.png" alt="image-20200311234550862" style="zoom:50%;" /></p>
<ul>
<li><p>高维空间十分稀疏，在“虫洞”中维度可能低一些；数据在流形行上的维度可能低于输入空间的维度，因此在流形的低维空间上就可能做数据的相似度等建模。</p>
<ul>
<li><blockquote>
<p>unsupervised representation learning</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h3><p><img src="/image-20200311234952926.png" alt="image-20200311234952926" style="zoom:50%;" /></p>
<h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><p><img src="/image-20200311235338823.png" alt="image-20200311235338823" style="zoom:50%;" /></p>
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p><img src="/image-20200311235453094.png" alt="image-20200311235453094" style="zoom:50%;" /></p>
<ul>
<li><p>不同超参，在训练集上分别训练，在验证集上检验效果，选效果最好的超参。</p>
<ul>
<li><blockquote>
<p>暴力方法：Auto-ML</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="2-感知机与多层感知机"><a href="#2-感知机与多层感知机" class="headerlink" title="2 感知机与多层感知机"></a>2 感知机与多层感知机</h2><h3 id="单层感知机"><a href="#单层感知机" class="headerlink" title="单层感知机"></a>单层感知机</h3><ul>
<li><p>最早的感知机针对二分类：符号函数作激活函数</p>
<script type="math/tex; mode=display">
\hat y = sgn\Big(\sum_i \theta_i x_i -T\Big)\notag</script><p>迭代$T_0$次，也即更新参数$\le T_0$次：</p>
<script type="math/tex; mode=display">
\theta=\theta +  y_tx_t,\quad if \ \hat y \not=y_t \\
\theta=\theta, \quad if \ \hat y =y_t \notag</script><p><img src="image-20200314221135319.png" style="zoom:50%;" /></p>
</li>
</ul>
<h4 id="收敛性"><a href="#收敛性" class="headerlink" title="收敛性"></a>收敛性</h4><p>  非线性可分情况下没法证明感知机的线性可分算法。但现实很多不是线性可分，所以只能接受这个假设带来的误差等。）收敛性可以用迭代到多少次就不再需要更新参数来衡量；或者说，当这些迭代中一共出现了多少个错分目标之、且我们针对这些更新了参数之后，就不再需要迭代更新参数了，也就是存在下图中的上界值$\Big(\frac{R}{\gamma}\Big)^2$</p>
<p><img src="/image-20200314221441453.png" alt="image-20200314221441453" style="zoom: 50%;" /></p>
<p> 收敛性证明：感知器的收敛速度其实比较慢。可以看到，$\gamma$越大，问题越简单，越线性可分，需要迭代的错误样本数$M$的上界越小，迭代越快，收敛越快；而$R$即最远的样本距离越大，而每次更新的步长是固定的，所以表明越难分类，所以需要迭代的错误样本数$M$的上界越大，迭代越慢，收敛越慢。</p>
<ul>
<li><p><img src="/image-20200314222934879.png" alt="image-20200314222934879" style="zoom: 50%;" /></p>
</li>
<li><p>本质上单层感知机表达的是<strong>线性函数</strong>，可以解决与或非，但是单层感知机不能解决异或，通过叠加可以。</p>
</li>
</ul>
<h3 id="MLP-Multilayer-Perceptrons-多层感知机（MLP，Multilayer-Perceptrons）-全连接网络（Fully-connected-network）"><a href="#MLP-Multilayer-Perceptrons-多层感知机（MLP，Multilayer-Perceptrons）-全连接网络（Fully-connected-network）" class="headerlink" title="MLP(Multilayer Perceptrons) 多层感知机（MLP，Multilayer Perceptrons）/全连接网络（Fully-connected network）"></a>MLP(Multilayer Perceptrons) 多层感知机（MLP，Multilayer Perceptrons）/全连接网络（Fully-connected network）</h3><h4 id="从单层到多层感知机"><a href="#从单层到多层感知机" class="headerlink" title="从单层到多层感知机"></a>从单层到多层感知机</h4><ul>
<li><p>多个感知机layering在一起可以表达universal approximator任意函数（有条件）。MLP的连接是<strong>稀疏</strong>的。</p>
<p><img src="/image-20200315001105621.png" alt="image-20200315001105621" style="zoom:50%;" /></p>
<p><img src="/image-20200315001821550.png" alt="image-20200315001821550" style="zoom:50%;" /></p>
</li>
<li><p>上述为布尔函数，感知机也可以表示实函数Real function。</p>
<p><img src="/image-20200315002509926.png" alt="image-20200315002509926" style="zoom:50%;" /></p>
<blockquote>
<p>如果感知机的激活函数是符号函数，那么边界其实是不可学习的，因为符号函数没有梯度，不能用基于梯度的反向传播等微积分算法。为了要求可学习，必须要求感知机是可求导的，采用可求导的模型后，可以近似拟合不能精确拟合边界。</p>
</blockquote>
</li>
<li><p>MLP模型</p>
<p><img src="/image-20200315153431413.png" alt="image-20200315153431413" style="zoom:50%;" /></p>
</li>
</ul>
<h4 id="激活函数-Activation-Functions"><a href="#激活函数-Activation-Functions" class="headerlink" title="激活函数 Activation Functions"></a>激活函数 Activation Functions</h4><ul>
<li><strong>非线性</strong>激活函数是神经网络的灵魂：嵌入激活函数是为了学习复杂的决策面。因为线性函数堆叠还是线性空间，所以要引入非线性。</li>
</ul>
<h5 id="隐藏层激活函数"><a href="#隐藏层激活函数" class="headerlink" title="隐藏层激活函数"></a>隐藏层激活函数</h5><h6 id="最常用的非线性激活函数：sigmoid"><a href="#最常用的非线性激活函数：sigmoid" class="headerlink" title="最常用的非线性激活函数：sigmoid"></a>最常用的非线性激活函数：sigmoid</h6><script type="math/tex; mode=display">
g(z)=sigmoid(z)= \sigma(z)= \frac{1}{1+e^{-z}}\notag</script><p><img src="/image-20200506225343868.png" alt="image-20200506225343868"></p>
<blockquote>
<p>问题：<strong>梯度消失</strong>（梯度饱和）</p>
<p>在大部分输入自变量区域中对应的<strong>梯度为0</strong>，对基于梯度的学习算法非常不友好，而深度学习基本都是基于梯度的算法。</p>
</blockquote>
<h6 id="其他激活函数"><a href="#其他激活函数" class="headerlink" title="其他激活函数"></a>其他激活函数</h6><ul>
<li><p>双曲正切tanh：和sigmoid一样存在梯度消失问题</p>
<p><img src="/image-20200320215713091.png" alt="image-20200320215713091" style="zoom:33%;" /><img src="/image-20200320215733947.png" alt="image-20200320215733947"></p>
</li>
<li><p>整流线性函数<strong>ReLu</strong></p>
<ul>
<li>很容易计算（computationally efficient）</li>
<li>很快收敛（converge much faster than sigmoid/tanh in practice）</li>
<li>梯度不会消失</li>
</ul>
<blockquote>
<p><strong>后面基本都会采用ReLu激活函数！</strong></p>
</blockquote>
</li>
</ul>
<p><img src="/image-20200315154348372.png" alt="image-20200315154348372" style="zoom: 67%;" /></p>
<ul>
<li><p>Leaky ReLU激活函数</p>
<p><img src="/image-20200320215747045.png" alt="image-20200320215747045" style="zoom:33%;" /></p>
</li>
</ul>
<h5 id="输出层激活函数：Softmax"><a href="#输出层激活函数：Softmax" class="headerlink" title="输出层激活函数：Softmax"></a>输出层激活函数：Softmax</h5><ul>
<li><p>将网络的输出变成概率</p>
<script type="math/tex; mode=display">
g(z_i) = \frac{e^{z_i}}{\sum_{j=1}^k e^{z_j} }\notag</script><ul>
<li><p>性质： winner takes all（赢者通吃），由于幂函数的性质，其中一个z比较大的话就会得到远大于其他的g值，对于分类是有好处的。</p>
</li>
<li><p>容易出现数值溢出：z比较大可能导致指数$e^{z_i}$溢出（overflow），故为了数值稳定性，作如下处理减掉最大的一个zm</p>
<script type="math/tex; mode=display">
g(z_i) = \frac{e^{z_i-z_m}}{\sum_{j=1}^k e^{z_j-z_m}},\quad m=argmax(z_j),z_j\in(-\infty,+\infty),\hat{y_j}\in[0,1],\sum\limits_{j=1}^k y_j =1 \notag</script></li>
</ul>
</li>
</ul>
<h4 id="Cost-function代价函数"><a href="#Cost-function代价函数" class="headerlink" title="Cost function代价函数"></a>Cost function代价函数</h4><ul>
<li>softmax函数转化概率</li>
<li>交叉熵损失</li>
</ul>
<p><img src="/image-20200315170950123.png" alt="image-20200315170950123" style="zoom:50%;" /></p>
<h2 id="3-反向传播-Back-propagation"><a href="#3-反向传播-Back-propagation" class="headerlink" title="3 反向传播 Back propagation"></a>3 反向传播 Back propagation</h2><h3 id="step1-前向传播：内存占用"><a href="#step1-前向传播：内存占用" class="headerlink" title="step1: 前向传播：内存占用"></a>step1: 前向传播：内存占用</h3><p><img src="/image-20200315172804385.png" alt="image-20200315172804385" style="zoom:50%;" /></p>
<h3 id="step2-反向传播"><a href="#step2-反向传播" class="headerlink" title="step2:反向传播"></a>step2:反向传播</h3><p>误差反向前传播，让网络每一层的参数都使得误差最小。</p>
<p><img src="/image-20200315172826434.png" alt="image-20200315172826434" style="zoom:67%;" /></p>
<h4 id="反向传播算法（BP）"><a href="#反向传播算法（BP）" class="headerlink" title="反向传播算法（BP）"></a>反向传播算法（BP）</h4><ul>
<li>BP的本质：<strong>链式法则</strong>的高效实现<ul>
<li>tf，pytorch等会对中间结构作一些优化，内存占用会低一些。</li>
</ul>
</li>
</ul>
<p><img src="/image-20200315173021691.png" alt="image-20200315173021691" style="zoom: 67%;" /></p>
<ul>
<li>计算残差（<strong>residual</strong>）</li>
</ul>
<p><img src="/image-20200315173912106.png" alt="image-20200315173912106" style="zoom: 67%;" /></p>
<p><img src="/image-20200315174131184.png" alt="image-20200315174131184" style="zoom:67%;" /></p>
<h3 id="计算梯度"><a href="#计算梯度" class="headerlink" title="计算梯度"></a>计算梯度</h3><ul>
<li><p>同时依赖于前向传播的激活值a和反向传播的残差$\delta$</p>
<p><img src="/image-20200315174634501.png" alt="image-20200315174634501" style="zoom:50%;" /></p>
</li>
</ul>
<h3 id="step3-更新参数（梯度下降GD）"><a href="#step3-更新参数（梯度下降GD）" class="headerlink" title="step3:更新参数（梯度下降GD）"></a>step3:更新参数（梯度下降GD）</h3><p><img src="/image-20200315175029456.png" alt="image-20200315175029456" style="zoom:50%;" /></p>
<h3 id="自动求导Automatic-differentiation"><a href="#自动求导Automatic-differentiation" class="headerlink" title="*自动求导Automatic differentiation"></a>*自动求导Automatic differentiation</h3><h4 id="比较不同微分方法"><a href="#比较不同微分方法" class="headerlink" title="比较不同微分方法"></a>比较不同微分方法</h4><p><img src="/image-20200315175337003.png" alt="image-20200315175337003" style="zoom:50%;" /></p>
<h4 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h4><p><img src="/image-20200315175604850.png" alt="image-20200315175604850"></p>
<blockquote>
<p>计算图细节：</p>
</blockquote>
<p><img src="/image-20200315175928409.png" alt="image-20200315175928409" style="zoom:50%;" /></p>
<h4 id="BP和自动求导比较"><a href="#BP和自动求导比较" class="headerlink" title="BP和自动求导比较"></a>BP和自动求导比较</h4><p><img src="/image-20200315180026584.png" alt="image-20200315180026584" style="zoom:50%;" /></p>
<ul>
<li><p>反向传播：只有一个计算图；网络所有梯度都要手动去写去实现</p>
</li>
<li><p>自动求导：在原先网络的基础上构造一个专门用于计算梯度的计算图，每个节点对应原来网络的每个节点的梯度显式表达式</p>
<ul>
<li>将所有可能用到的算子（乘法、加法、全连接层、卷积层等）对应的梯度都算出来，那么就可以直接用来搭出梯度计算图</li>
</ul>
<blockquote>
<p>早期theano，caffe不支持自动求导，tensorflow，pytorch都支持自动求导</p>
<ul>
<li>tf是符号式（symbolic）<ul>
<li>早期采用静态图，静态模型可以保存下来，以便后续直接load</li>
<li>大量适用于部署端</li>
</ul>
</li>
<li>torch是命令式（imperative）<ul>
<li>程序执行过程中可以看到中间所有变量结果，方便debug</li>
<li>但是不清楚之间的依赖关系，一般直接把源代码存下来</li>
<li>主要用于训练端</li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="4-训练技巧-Practical-training-strategies"><a href="#4-训练技巧-Practical-training-strategies" class="headerlink" title="4 训练技巧 Practical training strategies"></a>4 训练技巧 Practical training strategies</h2><h3 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h3><p><a href="https://arxiv.org/pdf/1206.5533.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1206.5533.pdf</a></p>
<h3 id="4-1-梯度下降的进阶版本"><a href="#4-1-梯度下降的进阶版本" class="headerlink" title="4.1 梯度下降的进阶版本"></a>4.1 梯度下降的进阶版本</h3><h4 id="4-1-1-随机梯度下降（SGD，stochastic-gradient-descent）"><a href="#4-1-1-随机梯度下降（SGD，stochastic-gradient-descent）" class="headerlink" title="4.1.1 随机梯度下降（SGD，stochastic gradient descent）"></a>4.1.1 随机梯度下降（SGD，stochastic gradient descent）</h4><ul>
<li><strong>降低计算复杂度</strong>——不再计算所有样本的梯度，改为小批量batch</li>
<li><strong>引入随机性</strong>——shuffle（洗牌）：对输入数据重新洗牌，打乱之后再随机取batch，能<strong>让网络在训练到局部极值的时候跳出局部极值</strong>。</li>
</ul>
<p><img src="/image-20200315181922400.png" alt="image-20200315181922400" style="zoom:50%;" /></p>
<pre><code>&gt; - iteration：对参数进行一次更新
&gt;
&gt; - epoch：将整个数据集扫描过一遍
</code></pre><h4 id="4-1-2-带冲量的SGD（SGD-with-Momentum）"><a href="#4-1-2-带冲量的SGD（SGD-with-Momentum）" class="headerlink" title="4.1.2 带冲量的SGD（SGD with Momentum）"></a>4.1.2 带冲量的SGD（SGD with Momentum）</h4><ul>
<li>冲量=上一时刻的冲量+当前时刻的梯度<ul>
<li>递推，具有累积效应，exponential moving</li>
<li><strong>避免局部极值</strong>：梯度为0时，冲量不为0，仍可以沿着冲量的方向继续更新参数</li>
</ul>
</li>
<li>冲量的高级版本<ul>
<li>RMSProp</li>
<li>ADAM</li>
</ul>
</li>
</ul>
<p><img src="/image-20200315182714055.png" alt="image-20200315182714055" style="zoom:50%;" /></p>
<h3 id="4-2-学习率衰减（Learning-Rate-Decay）"><a href="#4-2-学习率衰减（Learning-Rate-Decay）" class="headerlink" title="4.2 学习率衰减（Learning Rate Decay）"></a>4.2 学习率衰减（Learning Rate Decay）</h3><ul>
<li>x效果：目标函数loss先快速下降然后快饱和，然后再次快速下降</li>
<li>在一段时间迭代之后，将lr的值变小</li>
</ul>
<p><img src="/image-20200315183542054.png" alt="image-20200315183542054" style="zoom:50%;" /></p>
<blockquote>
<p>梯度下降中国，如果很快就陷入局部极值，往往是因为梯度不够大，如果梯度太大让网络发散不收敛了，再让梯度小一些。</p>
<p>大梯度：容易跳出局部极值，但是只能学到比较粗的、简单的pattern；</p>
<p>小梯度：不容易跳出局部极值，但是能学到比较复杂的pattern。</p>
</blockquote>
<h3 id="4-3-权重衰减（Weight-Decay）"><a href="#4-3-权重衰减（Weight-Decay）" class="headerlink" title="4.3 权重衰减（Weight Decay）"></a>4.3 权重衰减（Weight Decay）</h3><ul>
<li>对权重作正则化：让参数在一个受到约束的可行解的区域内，保证<strong>模型的复杂度较小</strong>。</li>
</ul>
<p><img src="/image-20200315184356960.png" alt="image-20200315184356960" style="zoom:50%;" /></p>
<h3 id="4-4-Dropout"><a href="#4-4-Dropout" class="headerlink" title="4.4 Dropout"></a>4.4 Dropout</h3><ul>
<li><p>前向传播将一定的神经元<strong>置0</strong>，神经元数量变少，网络变简单</p>
</li>
<li><p>伯努利分布：对任意一个神经元，以概率p置零</p>
</li>
<li><p>推理（inference）阶段：将置零的修正回来，如以0.5的概率dropout，那么值除以0.5也即乘以2.</p>
<p><img src="/image-20200315185247405.png" alt="image-20200315185247405" style="zoom:50%;" /></p>
</li>
</ul>
<h3 id="4-5-权重初始化（Weight-initialization）"><a href="#4-5-权重初始化（Weight-initialization）" class="headerlink" title="4.5 权重初始化（Weight initialization）"></a>4.5 权重初始化（Weight initialization）</h3><ul>
<li>0初始化参数效果不好，完全没办法训练。</li>
<li>Xavier 初始化，网络可收敛但是收敛较慢。</li>
<li>第三种初始化收敛较快。</li>
</ul>
<p><img src="/image-20200322104900689.png" alt="image-20200322104900689" style="zoom: 50%;" /><img src="/image-20200322105002893.png" alt="image-20200322105002893"></p>
<p><strong>Xavier Initialization</strong></p>
<ul>
<li>假设每层输入是均值为0方差为$\gamma$的随机变量，经过网络变换后希望网络的均值和方差不变，因为希望数据分布不发生变化。如果数据的均值和方差发生很大变化，它很容易逐层累积变得更大或更小，要么爆炸，要么消失。</li>
<li>所以可以得出权重的分布方差应该设为$1/n_{in}$</li>
</ul>
<p><img src="/image-20200322105002893.png" alt="image-20200322105002893"></p>
<ul>
<li>以均值0，方差一定值（Xavier Initialization）对某一层的参数进行初始化。</li>
</ul>
<p><strong>He Initialization</strong></p>
<ul>
<li>ReLU网络的初始化方式跟标准的网络初始化方式不太一样。即Xavier方法初始化对ReLU网络不收敛，改用<strong>He Initialization</strong>，补回relu函数使得数值变为0的那一半的方差。</li>
<li>其实Xavier在网络层数较少的时候是可以的（左图22层&lt;右图30层），因为累积效应在网络层数多的时候量变产生质变发生爆炸。</li>
</ul>
<p><img src="/image-20200315185505330.png" alt="image-20200315185505330" style="zoom: 67%;" /></p>
<h3 id="4-6批量归一化（Batch-Normalization）"><a href="#4-6批量归一化（Batch-Normalization）" class="headerlink" title="4.6批量归一化（Batch Normalization）"></a>4.6批量归一化（Batch Normalization）</h3><h4 id="4-6-1-motivation"><a href="#4-6-1-motivation" class="headerlink" title="4.6.1 motivation"></a>4.6.1 motivation</h4><ul>
<li><p>在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作<strong>Internal Covariate Shift</strong>（协变量偏移）。简言之，即a+1层要不停适应a层这种数据分布的变化。</p>
<p><img src="/image-20200322120820070.png" alt="image-20200322120820070" style="zoom:50%;" /></p>
<blockquote>
<p>最新研究工作表明，BN能够work并不是因为能解决ICS。</p>
<ul>
<li>在BN后加入噪声，分布不再和原来一样，即仍有covariate shift，但是仍然收敛得较好。</li>
</ul>
<p><img src="/image-20200322120957388.png" alt="image-20200322120957388" style="zoom:67%;" /></p>
<ul>
<li><p>不使用BN时网络的Lipchitz系数（目标函数对参数的导数的大小，越大表明目标函数越陡、越难优化，走一步可能很陡但是并没有达到很好地全局最优解，故容易陷入很多局部极值）很大，加入BN后网络的Lipchitz系数比较小、比较平稳，对应较光滑的landscape，更容易收敛。</p>
<p><img src="/image-20200322121601311.png" alt="image-20200322121601311" style="zoom:67%;" /></p>
</li>
<li><p>证明：使用BN之后的Lipchitz系数相较于之前是严格变小的</p>
<p><img src="/image-20200322121717842.png" alt="image-20200322121717842" style="zoom:67%;" /></p>
</li>
</ul>
</blockquote>
</li>
<li><p><strong>设计新的更高级网络的时候，应该是让网络变得更容易被优化，从这点出发可以加BN层，而不是对不能或不好优化的网络去设计更好的优化算法。</strong></p>
</li>
<li><p><strong>BN的计算代价和batch size成正比，这是BN的一个很大缺点。</strong></p>
</li>
</ul>
<p>（1）上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低。</p>
<p>（2）网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度。</p>
<h4 id="4-6-2-BN操作"><a href="#4-6-2-BN操作" class="headerlink" title="4.6.2 BN操作"></a>4.6.2 BN操作</h4><h5 id="（1）训练阶段"><a href="#（1）训练阶段" class="headerlink" title="（1）训练阶段"></a>（1）训练阶段</h5><ul>
<li><p>原本我们在数据分析中，常对输入数据进行减均值、除方差的操作，使得各维度特征的量纲一样。</p>
</li>
<li><p>BN对每一个通道（即每一维特征）<strong>减均值、除方差</strong>。均值和方差的值一般使用mini-batch中的n个样本的整体均值和方差。即对c个通道中的每一个，利用$n\times w \times h$个值来计算均值和方差。</p>
</li>
<li><p>原本均值$\mu$方差$\sigma ^2$的分布经过减均值、除方差变成了均值0方差1的分布，数据的分布发生了变化，所以再加上一组可学习参数$\gamma$和$\beta$的变换，一定程度上将其<strong>重构</strong>回来。</p>
<blockquote>
<p>第一步是归一化特征（的量纲）的范围，第二步是保证层与层之间传递的数据的原本分布。</p>
</blockquote>
<p><img src="/image-20200322115807275.png" alt="image-20200322115807275" style="zoom:50%;" /></p>
</li>
</ul>
<h5 id="（2）测试阶段"><a href="#（2）测试阶段" class="headerlink" title="（2）测试阶段"></a>（2）测试阶段</h5><ul>
<li>在测试（推理）阶段，使用的不再是mini-batch的均值和方差，采用moving average滑动平均（从收敛往前的batch的均值和方差乘以一个倍数的若干次方，后相加）版本的均值和方差，不会受到训练阶段任何一个mini batch的影响，就可以反映训练阶段整个数据集。</li>
</ul>
<p><img src="/image-20200322113443092.png" alt="image-20200322113443092" style="zoom:67%;" /></p>
<h4 id="4-6-3-BN的作用"><a href="#4-6-3-BN的作用" class="headerlink" title="4.6.3 BN的作用"></a>4.6.3 BN的作用</h4><ul>
<li><p><strong>改变了网络所能表达的函数，使得函数对应的loss landscape变得更加光滑。</strong></p>
</li>
<li><p><strong>BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度</strong>。BN通过规范化与线性变换使得每一层网络的输入数据的均值与方差都在一定范围内，使得后一层网络不必不断去适应底层网络中输入的变化，从而实现了网络中层与层之间的解耦，允许每一层进行独立学习，有利于提高整个神经网络的学习速度。</p>
<ul>
<li>加入BN之后可以用更大的学习率训练了，所以训练速度加快。</li>
</ul>
<p><img src="/image-20200322120703777.png" alt="image-20200322120703777" style="zoom:50%;" /></p>
</li>
<li><p><strong>BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题</strong> 。在不使用BN层的时候，由于网络的深度与复杂性，很容易使得底层网络变化累积到上层网络中，导致模型的训练很容易进入到激活函数的梯度饱和区；通过normalize操作可以让激活函数的输入数据落在梯度非饱和区，缓解梯度消失的问题；另外通过自适应学习 $\gamma$与 $\beta$又让数据保留更多的原始信息。 </p>
</li>
<li><p><strong>BN具有一定的正则化效果</strong>。在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，与Dropout通过关闭神经元给网络训练带来噪音类似，在一定程度上对模型起到了正则化的效果。 </p>
</li>
</ul>
<h4 id="4-6-4-进阶版BN"><a href="#4-6-4-进阶版BN" class="headerlink" title="4.6.4 进阶版BN"></a>4.6.4 进阶版BN</h4><ul>
<li>batch size足够大的情况下，BN是最好的；batch size小的时候，group normalization更好。 </li>
</ul>
<p><img src="/image-20200322122240085.png" alt="image-20200322122240085" style="zoom:67%;" /></p>
<p><img src="/image-20200322122412734.png" alt="image-20200322122412734" style="zoom: 50%;" /></p>
<h3 id="4-7-Babysitting-Learning"><a href="#4-7-Babysitting-Learning" class="headerlink" title="4.7 Babysitting Learning"></a>4.7 Babysitting Learning</h3><ul>
<li>训练误差抖动——学习率太大，降低学习率</li>
<li>有些神经元饱和——用初始化方法让初始化更好一些；对神经元的输出进行normalize</li>
<li>训练准确率一直涨，验证集准确率先升后降——<strong>early stopping，防止过拟合</strong></li>
</ul>
<p><img src="/image-20200315185933145.png" alt="image-20200315185933145" style="zoom: 67%;" /></p>
<h2 id="5-深度网络的表达能力Expressiveness-of-deep-networks"><a href="#5-深度网络的表达能力Expressiveness-of-deep-networks" class="headerlink" title="5 深度网络的表达能力Expressiveness of deep networks"></a>5 深度网络的表达能力Expressiveness of deep networks</h2><h3 id="神经网络的深度depth"><a href="#神经网络的深度depth" class="headerlink" title="神经网络的深度depth"></a>神经网络的深度depth</h3><ul>
<li><p>浅层但参数量很多的，尤其是全连接网络这样的模型，过拟合的程度可能更加严重。</p>
</li>
<li><p>对于两层感知器多边形区域模型，当$N\rightarrow +\infty$时，中间区域表示神经元输出值之和大于$N$，另外可以证明旁边的值都趋于$N/2$，这个时候多边形趋近于圆形。</p>
<p><img src="/image-20200316143951330.png" alt="image-20200316143951330" style="zoom:50%;" /></p>
</li>
<li><p>若同时减去$N/2$，则区域中间的判定表达式为$\sum y_i - N/2&gt;0$。</p>
</li>
<li><p>$K$个小圆“或”之后得到区域的并集，怎样表示？可以发现，每个小圆是“与”的结果，已经有2层，而多个小圆还需要“或”在一起，必然增加到3层。</p>
</li>
<li><p>两层网络的万能表示能力：如果不用三层以上怎样表示？对每个小圆，都有内部：$\sum y_i - N/2&gt;0$，</p>
<p>而外部：$\sum y_i - N/2=0$</p>
<p>所以对构成多边形区域的任意一个圆的内部有，$(\sum y_i-N/2)+(\sum y_i-N/2)+\cdots+(\sum y_i-N/2)&gt;0$，因为只会有一个圆对应的公式取大于号，其余都是等于0.</p>
<p>所以多边形区域可以表示为如下，累加每个小圆中的每个y即是累加整个区域的所有y：</p>
<script type="math/tex; mode=display">
\sum^{K}\sum_{i=1}^{N}(y_i-\frac{N}{2})=\sum_{i=1}^{KN}(y_i-\frac{N}{2})>0\notag</script><p><img src="/image-20200316144129313.png" alt="image-20200316144129313" style="zoom:50%;" /></p>
<blockquote>
<p>至此，虽然如上的两层感知机，可以表示复杂区域，但是付出的代价很庞大，甚至很难表达出来。并且小圆的表示需要N很大才能表达，已经不容易。</p>
</blockquote>
</li>
<li><p>浅层可能只能对输入空间进行少量粗略的对折，随着深度增加，每一层都会对输入空间进行进一步的对折，就会得到更加强的决策面。</p>
</li>
<li>深度网络每层需要更少的神经元，参数的效率（parameter efficiency）比浅层网络高得多。</li>
<li>深度网络不能被浅层网络近似，除非花极大的代价，即宽度很大。</li>
</ul>
<p><img src="/image-20200316151139272.png" alt="image-20200316151139272"></p>
<h3 id="神经网络的宽度width"><a href="#神经网络的宽度width" class="headerlink" title="神经网络的宽度width"></a>神经网络的宽度width</h3><ul>
<li>宽度也非常重要。浅层较宽的网络也不能被深层窄网络近似。</li>
</ul>
<p><img src="/image-20200316151923849.png" alt="image-20200316151923849" style="zoom:50%;" /></p>
<blockquote>
<p>我们需要比较深、比较宽的网络，表达能力更好。</p>
</blockquote>
<h3 id="神经网络可以把空间切分成多少线性区域"><a href="#神经网络可以把空间切分成多少线性区域" class="headerlink" title="神经网络可以把空间切分成多少线性区域"></a>神经网络可以把空间切分成多少线性区域</h3><ul>
<li><p>刻画了神经网络的表达能力，分类本质上就是将空间分为区域，同一类的区域可能不连续。</p>
</li>
<li><p>层深度的重要性（L在指数上），比宽度更重要（n不在指数上）。</p>
<p><img src="/image-20200316153519517.png" alt="image-20200316153519517" style="zoom:50%;" /></p>
</li>
<li><p>证明：空间折叠</p>
<ul>
<li>复杂函数（分类面）可以通过空间对折变成简单函数。</li>
<li>空间折叠法可以去找到（学习）分类边界的比较对称的局部，进而实现对折、 简化边界。  </li>
</ul>
<p><img src="/image-20200316153557151.png" alt="image-20200316153557151" style="zoom:50%;" /></p>
</li>
<li><p>ReLU为激活函数的MLP网络能够将d维的空间折叠出多少个区域？——构造法证明</p>
<ul>
<li><p>一维空间（一维输入）</p>
<p><img src="/image-20200318002036999.png" alt="image-20200318002036999" style="zoom:50%;" /></p>
</li>
<li><p>高维空间（三维输入）</p>
<p><img src="/image-20200318002500870.png" alt="image-20200318002500870" style="zoom:50%;" /></p>
<blockquote>
<p>fold其实和linear region是一样的。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>简单复杂的矛盾统一</p>
<ul>
<li><p>复杂函数通过折叠变简单，简单函数反而变复杂。</p>
</li>
<li><p>神经网络、傅里叶信号变化本质上都是坐标变化。FFT实际上也是抽取一系列标准正交（基函数）。原问题复杂经过坐标变换可能简单，反之则复杂。 </p>
<p><img src="/image-20200318003057057.png" alt="image-20200318003057057" style="zoom:50%;" /></p>
</li>
</ul>
</li>
</ul>
<h2 id="6-卷积神经网络-Convolutional-neural-network"><a href="#6-卷积神经网络-Convolutional-neural-network" class="headerlink" title="6 卷积神经网络 Convolutional neural network"></a>6 卷积神经网络 Convolutional neural network</h2><h3 id="6-1-CNN的提出"><a href="#6-1-CNN的提出" class="headerlink" title="6.1 CNN的提出"></a>6.1 CNN的提出</h3><h4 id="6-1-1-MLP存在的问题"><a href="#6-1-1-MLP存在的问题" class="headerlink" title="6.1.1 MLP存在的问题"></a>6.1.1 MLP存在的问题</h4><p>MLP是”万能逼近器“，图像识别本质上是映射函数，但是实际中有这样一些困难：</p>
<ul>
<li>MLP整体参数量庞大，超过计算机能够处理的半程。<ul>
<li>输入图像维度较高，将矩阵展开成向量输入，得到十万维以上的向量，输入神经元个数多。</li>
<li>为了用MLP对它进行映射，中间层的神经元个数往往也比较多，因为一般按照50%逐层递减。</li>
</ul>
</li>
<li>空间信息丢失。<ul>
<li>图像中不同位置是有空间关联结构的，变成向量会丢失空间的相对位置结构信息。</li>
<li>MLP不能很好适应视角、尺度、光照（viewpoint, scale, illumination variations）的变化。</li>
</ul>
</li>
</ul>
<h4 id="6-1-2-CNN的两个idea"><a href="#6-1-2-CNN的两个idea" class="headerlink" title="6.1.2 CNN的两个idea"></a>6.1.2 CNN的两个idea</h4><p><strong>（1）Local connectivity</strong></p>
<ul>
<li><p>人的视觉感受野细胞：只能看到空间的局部。</p>
</li>
<li><p>CNN中每个神经元：靠近输入层的神经元只负责处理输入图片中一部分的像素，相当于处理空间的局部；<strong>下一层神经元只负责处理前一层神经元的局部</strong>。</p>
</li>
<li><p><strong>局部性假设（locality assumption）</strong>：图像中的局部信息足以完成某种图像的识别。</p>
<blockquote>
<p>当有些场景的输入矩阵元素之间没有相邻关系时，不满足局部性假设，其实是不能用卷积神经网络的。</p>
<p>又如手工构造的特征，相互独立时，也不具有局部性，不能使用卷积网络，或者使用效果不好。</p>
</blockquote>
<p><img src="/image-20200319105408387.png" alt="image-20200319105408387" style="zoom:50%;" /></p>
</li>
</ul>
<p><strong>（2）参数共享（Parameter sharing）</strong></p>
<ul>
<li><p>当任意一个神经元代表的pattern（模板template）在图像上平移扫描时，模板的参数不应该变化，因为一个pattern代表一个特定的待识别对象，因此模板权重固定。</p>
</li>
<li><p><strong>平移不变性假设（Shift invariance assumption）:</strong></p>
<ul>
<li>当一个特征在一个空间位置上适用，那么在所有空间位置上都应该是一样的。</li>
</ul>
</li>
<li><p>参数共享：保证不同template在各个区域都是一样的；同时让网络参数大大下降。</p>
<blockquote>
<p> 实际很难获得平移不变性。</p>
</blockquote>
<p><img src="/image-20200319110624279.png" alt="image-20200319110624279" style="zoom:50%;" /></p>
</li>
</ul>
<h3 id="6-2-CNN"><a href="#6-2-CNN" class="headerlink" title="6.2 CNN"></a>6.2 CNN</h3><h4 id="6-2-1-卷积"><a href="#6-2-1-卷积" class="headerlink" title="6.2.1 卷积"></a>6.2.1 卷积</h4><ul>
<li><p>让$\tau $从-∞滑动到+∞。两函数交会时，计算交会范围中两函数乘积的积分值。换句话说，我们是在计算一个滑动的的加权总和(weighted-sum)。也就是使用$g(t-\tau)$当做加权函数，来对取$f(\tau)$加权值。 </p>
<blockquote>
<p>下图中积分函数（黑线）的起始和终止横坐标取决于f和g函数的重叠的横坐标。</p>
</blockquote>
</li>
<li><p>f原函数——图像</p>
</li>
<li><p>g 加权函数——模板（template）/滤波器/卷积核</p>
<ul>
<li>加权：强调输入函数中重要的区域</li>
</ul>
</li>
</ul>
<p><img src="/image-20200319111254790.png" alt="image-20200319111254790" style="zoom:50%;" /></p>
<h4 id="6-2-2-互相关cross-correlation"><a href="#6-2-2-互相关cross-correlation" class="headerlink" title="6.2.2 互相关cross-correlation"></a>6.2.2 互相关cross-correlation</h4><ul>
<li>可滑动的内积：度量任意两个函数/序列的相似度。</li>
</ul>
<p><img src="/image-20200319140436418.png" alt="image-20200319140436418" style="zoom:50%;" /></p>
<h4 id="6-2-3-卷积、互相关的关系"><a href="#6-2-3-卷积、互相关的关系" class="headerlink" title="6.2.3 卷积、互相关的关系"></a>6.2.3 卷积、互相关的关系</h4><ul>
<li><p>等价，相差一个变换</p>
<p><img src="/image-20200319150424650.png" alt="image-20200319150424650" style="zoom:50%;" /></p>
</li>
</ul>
<h4 id="6-2-4-CNN"><a href="#6-2-4-CNN" class="headerlink" title="6.2.4 CNN"></a>6.2.4 CNN</h4><ul>
<li>二维称kernel，三维称filter</li>
</ul>
<p><img src="/image-20200319151350569.png" alt="image-20200319151350569" style="zoom:50%;" /></p>
<ul>
<li><p>卷积其实就是用一个template在图像上扫，将感兴趣的pattern域扫描出来。</p>
<p><img src="/image-20200319151806867.png" alt="image-20200319151806867" style="zoom:50%;" /></p>
</li>
<li><p>卷积核的size越大，后面特征图的宽度越小。</p>
<p><img src="/image-20200320151950770.png" alt="image-20200320151950770" style="zoom:50%;" /></p>
</li>
<li><p>参数共享：一个卷积核在同一层上，一个图像的不同位置上，参数是一样的。</p>
<p><img src="/image-20200320152154321.png" alt="image-20200320152154321" style="zoom:50%;" /></p>
</li>
<li><p><strong>卷积核的个数 = 下一层特征图的层数/通道数</strong></p>
</li>
<li><p><strong>卷积核的深度 =  前一层特征图的深度（通道数）</strong></p>
<p><img src="/image-20200320175245513.png" alt="image-20200320175245513" style="zoom:50%;" /></p>
<blockquote>
<p>可学习的卷积核是深度学习的核心。</p>
</blockquote>
</li>
<li><p><strong>卷积层数加深，感受野越来越大。</strong></p>
</li>
</ul>
<h4 id="6-2-5-卷积的扩展"><a href="#6-2-5-卷积的扩展" class="headerlink" title="6.2.5 卷积的扩展"></a>6.2.5 卷积的扩展</h4><h5 id="（1）空洞卷积（Dilated-convolution）"><a href="#（1）空洞卷积（Dilated-convolution）" class="headerlink" title="（1）空洞卷积（Dilated convolution）"></a>（1）空洞卷积（Dilated convolution）</h5><ul>
<li><p>需要更大的感受野时，如当同时需要识别大尺度和小尺度目标时，这时可以使用空洞卷积。</p>
<p><img src="/image-20200320173846279.png" alt="image-20200320173846279" style="zoom:50%;" /></p>
</li>
</ul>
<h5 id="（2）标准卷积、带步幅stride的卷积、空洞卷积"><a href="#（2）标准卷积、带步幅stride的卷积、空洞卷积" class="headerlink" title="（2）标准卷积、带步幅stride的卷积、空洞卷积"></a>（2）标准卷积、带步幅stride的卷积、空洞卷积</h5><p><img src="/image-20200320174015059.png" alt="image-20200320174015059" style="zoom:50%;" /></p>
<h4 id="6-2-6-步幅和填充-（stride，-padding）"><a href="#6-2-6-步幅和填充-（stride，-padding）" class="headerlink" title="6.2.6 步幅和填充 （stride， padding）"></a>6.2.6 步幅和填充 （stride， padding）</h4><h5 id="（1）步幅stride"><a href="#（1）步幅stride" class="headerlink" title="（1）步幅stride"></a>（1）步幅stride</h5><ul>
<li><p>卷积核窗口每次移动的步长。</p>
</li>
<li><p>步幅可以大幅降低输出的特征图在空间上的维度大小（长宽）。</p>
</li>
<li><p>用于控制网络输出特征图大小。</p>
<p><img src="/image-20200320175652483.png" alt="image-20200320175652483" style="zoom:50%;" /></p>
</li>
</ul>
<h5 id="（2）填充padding"><a href="#（2）填充padding" class="headerlink" title="（2）填充padding"></a>（2）填充padding</h5><ul>
<li><p>按照一定步幅移动时，移动到最边上可以没有完整的卷积核大小原图对应到filter上了，这个时候padding用来填充边缘。</p>
</li>
<li><p>或者当不希望图像特征尺寸发生变化时，作填充。</p>
<p><img src="/image-20200320180203873.png" alt="image-20200320180203873" style="zoom:50%;" /></p>
</li>
</ul>
<h5 id="Summary：卷积操作特征图大小计算公式"><a href="#Summary：卷积操作特征图大小计算公式" class="headerlink" title="Summary：卷积操作特征图大小计算公式"></a>Summary：卷积操作特征图大小计算公式</h5><ul>
<li><p>stride=1，无padding</p>
<script type="math/tex; mode=display">
(n-f+1) \times(n-f+1)
\notag</script></li>
<li><p>stride = 1, padding = p即每个边都扩充p个像素</p>
<script type="math/tex; mode=display">
((n+2p)-f+1) \times((n+2p)-f+1) \\= (n+2p-f+1) \times(n+2p-f+1) \notag</script></li>
<li><p>stride = s, padding = p且没有出格（也就是n+2p-f可以刚好分成s一份的若干份，再加上最左边一份）</p>
<script type="math/tex; mode=display">
\Bigg(\frac{(n+2p)-f}{s} +1 \Bigg)\times \Bigg(\frac{(n+2p)-f}{s} +1 \Bigg)
 \notag</script></li>
<li><p>stride = s, padding = p且出格，这个时候应该向下取整</p>
</li>
</ul>
<script type="math/tex; mode=display">
\Bigg\lfloor \frac{(n+2p)-f}{s} +1   \Bigg\rfloor \times \Bigg\lfloor \frac{(n+2p)-f}{s} +1   \Bigg\rfloor
\notag</script><blockquote>
<p>理解可见下图：</p>
<p><img src="/image-20200320214219283.png" alt="image-20200320214219283" style="zoom: 33%;" /></p>
</blockquote>
<h4 id="6-2-7卷积层的超参数"><a href="#6-2-7卷积层的超参数" class="headerlink" title="6.2.7卷积层的超参数"></a>6.2.7卷积层的超参数</h4><p> <img src="/image-20200320231845267.png" alt="image-20200320231845267" style="zoom: 50%;" /></p>
<h4 id="6-2-8-池化（Pooling）-下采样"><a href="#6-2-8-池化（Pooling）-下采样" class="headerlink" title="6.2.8 池化（Pooling）/ 下采样"></a>6.2.8 池化（Pooling）/ 下采样</h4><ul>
<li><p>当图像较大时，往往用来对图像的特征图的size进行约减。</p>
<p><img src="/image-20200320233013119.png" alt="image-20200320233013119" style="zoom:50%;" /></p>
</li>
<li><p>池化层曾试图增强平移不变性。但是2019年证明pooling无法获得平移不变性。</p>
</li>
<li><p>升级版本：Spatial Pyramid Pooling</p>
<ul>
<li>不同尺度的目标对应不同size的pooling进行操作，从而得到多尺度特征。</li>
</ul>
<p><img src="/image-20200320233148058.png" alt="image-20200320233148058" style="zoom:50%;" /></p>
</li>
</ul>
<h4 id="6-2-9-卷积层、激活函数、池化层组成卷积网络"><a href="#6-2-9-卷积层、激活函数、池化层组成卷积网络" class="headerlink" title="6.2.9 卷积层、激活函数、池化层组成卷积网络"></a>6.2.9 卷积层、激活函数、池化层组成卷积网络</h4><p><img src="/image-20200320233351548.png" alt="image-20200320233351548" style="zoom:50%;" /></p>
<h5 id="（1）LeNet"><a href="#（1）LeNet" class="headerlink" title="（1）LeNet"></a>（1）LeNet</h5><ul>
<li>尺度小、通道数多的特征图，是原始图像的高层特征表达，因为每一个通道代表一个特征，即特征丰富度提高。</li>
<li>在高维特征的基础上，加MLP网络。</li>
</ul>
<p>​    <img src="/image-20200320233454513.png" alt="image-20200320233454513" style="zoom:50%;" /></p>
<h5 id="（2）AlexNet"><a href="#（2）AlexNet" class="headerlink" title="（2）AlexNet"></a>（2）AlexNet</h5><p>算力带来的结果：</p>
<ul>
<li>层数变多</li>
<li>卷积核数目变多</li>
<li>输入图像大小更大</li>
<li>输入通道数变多</li>
</ul>
<p><img src="/image-20200320233853598.png" alt="image-20200320233853598" style="zoom:50%;" /></p>
<p>contribution：</p>
<ul>
<li>配出来了网络参数</li>
<li>引入数据预处理等处理技巧<ul>
<li>局部归一化（local response normalization）</li>
<li>dropout对网络的训练也非常重要，因为网络参数量很大，需要将全连接的一些编码drop掉，否则容易过拟合。</li>
<li>数据增广</li>
</ul>
</li>
</ul>
<h4 id="6-2-10-可视化特征图和卷积核"><a href="#6-2-10-可视化特征图和卷积核" class="headerlink" title="6.2.10 可视化特征图和卷积核"></a>6.2.10 可视化特征图和卷积核</h4><h5 id="（1）可视化特征图"><a href="#（1）可视化特征图" class="headerlink" title="（1）可视化特征图"></a>（1）可视化特征图</h5><ul>
<li><p>人眼越容易理解、分辨的内容越处于low-level。high-level细节信息丢失人眼不容易理解。深度学习本质上在做特征学习，将这些特征进行解耦，数据在解耦之后的特征表达之下，有可能就变得线性可分了。</p>
</li>
<li><p>不同卷积核学到的特征不一样。</p>
<p><img src="/image-20200320234827518.png" alt="image-20200320234827518" style="zoom:50%;" /></p>
</li>
</ul>
<h5 id="（2）可视化滤波器-卷积核"><a href="#（2）可视化滤波器-卷积核" class="headerlink" title="（2）可视化滤波器/卷积核"></a>（2）可视化滤波器/卷积核</h5><ul>
<li>对任一卷积核，如果这个卷积核使输入图像的激活值达到最大，就认为这个卷积核是在捕捉这个输入图像对应的pattern。即跟滤波器相关的图像激活最大。</li>
<li>卷积核从底层到上层逐渐从细节到抽象：边缘算子、纹理、object path、object</li>
</ul>
<p><img src="/image-20200320235105330.png" alt="image-20200320235105330" style="zoom:50%;" /></p>
<h3 id="6-3-反向传播算法BP（backpropagation）"><a href="#6-3-反向传播算法BP（backpropagation）" class="headerlink" title="6.3 反向传播算法BP（backpropagation）"></a>6.3 反向传播算法BP（backpropagation）</h3><h4 id="6-3-1-前向传播"><a href="#6-3-1-前向传播" class="headerlink" title="6.3.1 前向传播"></a>6.3.1 前向传播</h4><p><img src="/image-20200321213626408.png" alt="image-20200321213626408" style="zoom:50%;" /></p>
<h4 id="6-3-2-反向传播"><a href="#6-3-2-反向传播" class="headerlink" title="6.3.2 反向传播"></a>6.3.2 反向传播</h4><h5 id="池化层的bp计算"><a href="#池化层的bp计算" class="headerlink" title="池化层的bp计算"></a>池化层的bp计算</h5><ul>
<li><p>正向是通过先接池化、再接激活函数。所以反向求残差是先经过激活、再经过池化。</p>
</li>
<li><p>pooling层是非参数化的，没有参数，相当于是线性的，也就是说pooling之后对之前求导为1，但因为残差需要回传，所以其实是要进行上采样将如2×2变成4×4.</p>
<blockquote>
<p>max pooling需要纪录每次最大值的位置。（正向）</p>
</blockquote>
</li>
</ul>
<p><img src="/image-20200321213922907.png" alt="image-20200321213922907" style="zoom:50%;" /></p>
<h5 id="卷积层的bp计算"><a href="#卷积层的bp计算" class="headerlink" title="卷积层的bp计算"></a>卷积层的bp计算</h5><ul>
<li>不同于MLP全连接，在CNN中由于<strong>局部连接</strong>（local connectivity），上一层神经元对下一层的影响在k * k范围内。所以对某一个$z_{ij}$求导，要找出所有受它影响的下一层神经元。</li>
<li>考虑输出一个通道：</li>
</ul>
<p><img src="/image-20200321224018669.png" alt="image-20200321224018669" style="zoom: 67%;" /></p>
<p><img src="/image-20200321225255153.png" alt="image-20200321225255153" style="zoom:50%;" /></p>
<ul>
<li><p>实际输出d个通道：d个卷积核都会对某一个$z_{ij}$求导，会对应得到d个通道的结果</p>
<p><img src="/image-20200321225429192.png" alt="image-20200321225429192" style="zoom:50%;" /></p>
</li>
</ul>
<h5 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h5><p><img src="/image-20200321225828040.png" alt="image-20200321225828040" style="zoom: 67%;" /></p>
<h4 id="6-2-3-参数更新"><a href="#6-2-3-参数更新" class="headerlink" title="6.2.3 参数更新"></a>6.2.3 参数更新</h4><ul>
<li>小批量梯度下降</li>
</ul>
<p><img src="/image-20200321225938539.png" alt="image-20200321225938539" style="zoom:67%;" /></p>
<h3 id="6-4-卷积网络的实际训练技巧（Practical-training-strategies）"><a href="#6-4-卷积网络的实际训练技巧（Practical-training-strategies）" class="headerlink" title="6.4 卷积网络的实际训练技巧（Practical training strategies）"></a>6.4 卷积网络的实际训练技巧（Practical training strategies）</h3><h4 id="6-4-1-Weight-initialization"><a href="#6-4-1-Weight-initialization" class="headerlink" title="6.4.1 Weight initialization"></a>6.4.1 Weight initialization</h4><p>见4.3</p>
<h4 id="6-4-2-Batch-normalization"><a href="#6-4-2-Batch-normalization" class="headerlink" title="6.4.2 Batch normalization"></a>6.4.2 Batch normalization</h4><p>见4.6</p>
<h3 id="6-5-不变性和等变性Invariance-vs-Equivariance"><a href="#6-5-不变性和等变性Invariance-vs-Equivariance" class="headerlink" title="6.5 不变性和等变性Invariance vs. Equivariance"></a>6.5 不变性和等变性Invariance vs. Equivariance</h3><h4 id="6-5-0-不变性和等变性Invariance-vs-Equivariance"><a href="#6-5-0-不变性和等变性Invariance-vs-Equivariance" class="headerlink" title="6.5.0 不变性和等变性Invariance vs. Equivariance"></a>6.5.0 不变性和等变性Invariance vs. Equivariance</h4><ul>
<li><p>等变性</p>
<p><img src="/image-20200404174221618.png" alt="image-20200404174221618"></p>
<ul>
<li>对一些细节的任务很重要，如眼睛和嘴巴互换的图像，如果不能把这种变化检测出来，那么网络就会失效。</li>
<li><strong>卷积操作本身是等变性的，但是整个网络不等变。（因为除了卷积还有池化，BN等）</strong></li>
</ul>
</li>
<li><p>不变性</p>
<p><img src="/image-20200404174628820.png" alt="image-20200404174628820"></p>
<ul>
<li>位置/平移不变性</li>
<li>CNN通过加入池化层来实现对小的变化（如目标平移变化）的不变性（的稳定识别结果）</li>
</ul>
</li>
<li><p>不变性和等变性是矛盾的。</p>
</li>
<li><p>但是CNN的设计中方正的卷积核去扫描图像，就是固有地使它限于只能建模较大的transformation（形变）。而对光照变化、背景重叠、视角变化、形变、类内差异大于类间差异、尺度变化、旋转、部分目标等存在一定的问题。</p>
</li>
</ul>
<h4 id="6-5-1-数据增广（Data-augmentation）"><a href="#6-5-1-数据增广（Data-augmentation）" class="headerlink" title="6.5.1 数据增广（Data augmentation）"></a>6.5.1 数据增广（Data augmentation）</h4><p>既然对这些变换的学习有难度，那我们就把这些变换的数据也加入训练数据中。</p>
<p><img src="/image-20200404175850464.png" alt="image-20200404175850464"></p>
<ul>
<li><p>翻转</p>
</li>
<li><p>旋转</p>
</li>
<li><p>加高斯噪声</p>
</li>
<li><p>剪裁……</p>
</li>
<li><p>风格化增广：为了避免CNN对某种特征的学习产生偏见，如相对形状，对纹理的特征学习得更好，则设法增强多种纹理，减弱CNN对于纹理学习的偏好。（在真实数据集上训练的CNN是偏向于识别纹理的！）</p>
<p><img src="/image-20200404180316145.png" alt="image-20200404180316145" style="zoom:67%;" /></p>
</li>
<li><p>context增广：为了避免CNN学到某种物体和某种物体经常一起出现这样的上下文信息</p>
<p><img src="/image-20200404180529609.png" alt="image-20200404180529609" style="zoom:67%;" /></p>
</li>
</ul>
<h4 id="6-5-2-平移不变性和等变性Rethinking-shift-invariance-and-equivariance"><a href="#6-5-2-平移不变性和等变性Rethinking-shift-invariance-and-equivariance" class="headerlink" title="6.5.2 平移不变性和等变性Rethinking shift invariance and equivariance"></a>6.5.2 平移不变性和等变性Rethinking shift invariance and equivariance</h4><ul>
<li><p>平移等变性shift  equivariance：先对图像进行平移再进行特征提取，和先特征提取再平移特征图的结果是一样的。</p>
<p><img src="/image-20200404180918667.png" alt="image-20200404180918667"></p>
</li>
<li><p>平移不变性shift invariance ：输入进不进行平移，抽取到的特征都是一样的，这样的特征则具有平移不变性。（很重要！）</p>
<p><img src="/image-20200404181101851.png" alt="image-20200404181101851"></p>
</li>
<li><p><strong>深度CNN不具有平移不变性！</strong>（也不具有等变性）</p>
<ul>
<li><p>因为CNN中有一些模块不具有连续性，是离散函数。如pooling，这种阶跃式的处理其实是相当危险的，小小的一点变化输出就有很大变化，以下图的一维的max pooling为例：</p>
<p><img src="/image-20200404203638226.png" alt="image-20200404203638226" style="zoom: 67%;" /></p>
</li>
</ul>
</li>
<li><p>解决max pooling不平滑的问题——anti-aliased max-pooling(ICML2019)</p>
<ul>
<li><p>首先将max pooling等价于两步：密集的取max（可以stride = 1，可以通过padding等保持维度不变），和降采样。</p>
</li>
<li><p>使用防锯齿的anti-aliased操作进行平滑：加入blur kernel平滑经过max之后的特征图，模糊掉相邻格子之间的阶跃型的差异，弱化锯齿，一定程度上保持数值的连续性。</p>
</li>
<li><p><img src="/image-20200404204009462.png" alt="image-20200404204009462" style="zoom: 67%;" /></p>
</li>
</ul>
</li>
</ul>
<h4 id="6-5-3-Model-revolution-still-ongoing"><a href="#6-5-3-Model-revolution-still-ongoing" class="headerlink" title="6.5.3 Model revolution: still ongoing"></a>6.5.3 Model revolution: still ongoing</h4><ul>
<li>CNN最大的缺点：丢失了spatial relation空间关系信息</li>
<li>人视觉系统和机器CNN都是有bias的。</li>
<li>矛头指向max pooling：不具备平移不变性；不具备保留spatial relation的能力。</li>
<li>输入数据不可能覆盖整个输入空间，因为有维度灾难。除了分类正确的不变性的性质，capture到的特征还应该足以用来重构原来的输入，也就是等变性。</li>
</ul>
<p><img src="/image-20200404205424868.png" alt="image-20200404205424868" style="zoom: 67%;" /></p>
<ul>
<li>胶囊网络：扩展的卷积特征图，每一个通道的每一个位置上不再只是一个标量，而是矢量，因此增加了信息量，可能表达更多的spatial relation或者direction方向等信息。</li>
</ul>
<p><img src="/image-20200404210031103.png" alt="image-20200404210031103" style="zoom: 67%;" /></p>
<h2 id="7-标准卷积神经网络架构Standard-Architectures"><a href="#7-标准卷积神经网络架构Standard-Architectures" class="headerlink" title="7 标准卷积神经网络架构Standard Architectures"></a>7 标准卷积神经网络架构Standard Architectures</h2><h3 id="7-1-早期8层较浅深度网络"><a href="#7-1-早期8层较浅深度网络" class="headerlink" title="7.1 早期8层较浅深度网络"></a>7.1 早期8层较浅深度网络</h3><p><img src="/image-20200426121216570.png" alt="image-20200426121216570" style="zoom:67%;" /></p>
<h4 id="7-1-1-AlexNet"><a href="#7-1-1-AlexNet" class="headerlink" title="7.1.1 AlexNet"></a>7.1.1 AlexNet</h4><p><img src="/image-20200409003136442.png" alt="image-20200409003136442" style="zoom: 67%;" /></p>
<ul>
<li><p>分布式训练（两块GPU）Multi-GPU训练</p>
</li>
<li><p>第一个使用ReLU的卷积网络，可以避免梯度消失</p>
</li>
<li><p>采用了data augmentation数据增广，说明即使对于ImageNet这样大规模数据集，数据增广仍然非常重要</p>
</li>
<li><p>使用了多个网络进行集成，准确率有进一步提升</p>
</li>
<li><p>全连接层参数规模大</p>
</li>
<li><p>训练技巧：</p>
<ul>
<li><p>局部响应正则化 Local Response Normalization：在相邻神经元之间引入竞争（用上一层神经元邻居的激活来做一个加权，对神经元的激活作一个normalization），有利于网络获得相对更可解释的结果</p>
<p><img src="/image-20200409003737584.png" alt="image-20200409003737584" style="zoom:50%;" /></p>
</li>
<li><p>使用dropout=0.5</p>
</li>
<li><p>使用L2 weight decay 5e-4</p>
</li>
<li><p>多GPU训练和数据增广</p>
</li>
<li><p>SGD with momentum 0.9</p>
<ul>
<li>lr=0.01, reduced by 10 manually when validation accuracy plateaus</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="7-1-2-ZFNet"><a href="#7-1-2-ZFNet" class="headerlink" title="7.1.2 ZFNet"></a>7.1.2 ZFNet</h4><p>（到底是网络架构重要还是参数重要？网络参数配置很重要！）</p>
<ul>
<li><p>相对于AlexNet，架构没有变化（8层），每一层的卷积核个数、大小、通道数量等变化，相当于做了一个暴力超参数调优，降低了错误率。</p>
<p><img src="/image-20200409145623447.png" alt="image-20200409145623447" style="zoom: 67%;" /></p>
</li>
<li><p>对后续工作的影响：</p>
<ul>
<li>卷积核大小会倾向于小的；</li>
<li>网络上层的通道数相对来说更多，通道越多capture的特征越多。</li>
</ul>
</li>
</ul>
<h3 id="7-2-较深、架构更复杂网络"><a href="#7-2-较深、架构更复杂网络" class="headerlink" title="7.2 较深、架构更复杂网络"></a>7.2 较深、架构更复杂网络</h3><p><img src="/image-20200426121346801.png" alt="image-20200426121346801" style="zoom:67%;" /></p>
<h4 id="7-2-1-VGG"><a href="#7-2-1-VGG" class="headerlink" title="7.2.1 VGG"></a>7.2.1 VGG</h4><ul>
<li><p>用更深的网络，更小的卷积核，获得同样的感受野的大小。</p>
<ul>
<li>更深的网络有更好的非线性；</li>
<li>但是更难训练，故有可能需要做预训练。</li>
</ul>
</li>
<li><p>局部响应正则化 Local Response Normalization（LRN）并不重要</p>
<ul>
<li>集成虽然可以获得更好的效果，但是我们还是倾向于用单一模型（single model），集成模型用于推理阶段的复杂性不能接受。</li>
</ul>
</li>
<li><p>全连接层特征的泛化能力较好，可以将特征泛化到下游的分类、定位等任务上去。</p>
<p><img src="/image-20200409150831659.png" alt="image-20200409150831659" style="zoom:67%;" /></p>
</li>
<li><p>参数爆炸问题主要存在于全连接层：</p>
<p><img src="/image-20200409151024069.png" alt="image-20200409151024069" style="zoom: 50%;" /></p>
<ul>
<li><p>1×1卷积/ 点卷积（1×1convolution / point-wise convolution)</p>
<ul>
<li><p>kernel size为1×1的标准卷积</p>
</li>
<li><p>上一层特征图经过点卷积，大小不会发生变化，但是通道数可以根据具体需求变得更多或者更少。</p>
<p><img src="/image-20200409151333377.png" alt="image-20200409151333377" style="zoom:50%;" /></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>神经网络设计时，层与层之间不应该在空间维度上衰减得太快。</strong>故希望更多的通道捕捉更多更好的特征</p>
<ul>
<li>更大的卷积核倾向于模糊特征，因为是更大范围的平均</li>
<li>更大的步幅导致图像中相邻像素的细节丢失</li>
</ul>
</blockquote>
<h4 id="7-2-2-网中网（Network-in-Network，NIN）"><a href="#7-2-2-网中网（Network-in-Network，NIN）" class="headerlink" title="7.2.2 网中网（Network in Network，NIN）"></a>7.2.2 网中网（Network in Network，NIN）</h4><ul>
<li>降低网络中间层的resolution（分辨率）</li>
<li>引入点卷积，增加通道数，以增大特征提取能力；同时相对普通卷积也降低了参数规模</li>
<li><strong>全局平均池化Global average pooling</strong>：10×10×2048——1×2048<ul>
<li>增加特征表示的平移不变性：使得最后特征对空间平移更加稳定，eg 目标的空间位置不同，特征都不受影响</li>
<li>缺点：信息损失太大，要通过前面的层学到对global average pooling友好的特征，以补偿这种损失。</li>
</ul>
</li>
</ul>
<p><img src="/image-20200409153544435.png" alt="image-20200409153544435" style="zoom:67%;" /></p>
<h3 id="7-3-魔改网络时代"><a href="#7-3-魔改网络时代" class="headerlink" title="7.3 魔改网络时代"></a>7.3 魔改网络时代</h3><h4 id="7-3-1-GoogLeNet（Inception-v1）"><a href="#7-3-1-GoogLeNet（Inception-v1）" class="headerlink" title="7.3.1 GoogLeNet（Inception-v1）"></a>7.3.1 GoogLeNet（Inception-v1）</h4><h5 id="7-3-1-1-基本特点"><a href="#7-3-1-1-基本特点" class="headerlink" title="7.3.1.1 基本特点"></a>7.3.1.1 基本特点</h5><ul>
<li><p>motivation：希望设计更深的网络；参数量更少，计算效率更高，希望对移动端更友好</p>
<p><img src="/image-20200409154752399.png" alt="image-20200409154752399" style="zoom:67%;" /></p>
</li>
<li><p>22层：<strong>更深</strong></p>
</li>
<li><p>参数量是AlexNet的1/12</p>
</li>
<li><p>中间堆叠了inception modules</p>
</li>
<li><p>有3个分类器</p>
<ul>
<li><p>2个中间辅助分类器</p>
</li>
<li><p>1个最终分类器</p>
<blockquote>
<p>说明<strong>梯度消失</strong>了，网络层数太深，最后一层的分类器没有办法将足够的梯度传回来，故需要在中间层加deep supervision，但这样无法保证中间层学到的特征是不是足够底层的。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h5 id="7-3-1-2-inception-module的发展过程"><a href="#7-3-1-2-inception-module的发展过程" class="headerlink" title="7.3.1.2 inception module的发展过程"></a>7.3.1.2 inception module的发展过程</h5><p>（1）Naive Inception module</p>
<ul>
<li><p>网中网的思想，将多个不同尺度的卷积核同时放在上一层到下一层之间</p>
<ul>
<li>不同大小感受野的卷积核，同时对空间不同尺度的信息有更好的捕捉能力</li>
<li>不同尺度特征连接起来，提高了特征的丰富程度</li>
</ul>
<p><img src="/image-20200409161341587.png" alt="image-20200409161341587" style="zoom:67%;" /></p>
<ul>
<li><strong>更宽</strong>：在宽度方向增加卷积核，增加了参数量（total：854M）——后来深度学习发展的思想：网络不止越深越好，宽度也很重要。</li>
</ul>
<p><img src="/image-20200426125632381.png" alt="image-20200426125632381" style="zoom:67%;" /></p>
</li>
</ul>
<p>（2）利用点卷积思想，先降低通道数（<strong>将降维思想引入深度学习</strong>）</p>
<p><img src="/image-20200409204750437.png" alt="image-20200409204750437" style="zoom:67%;" /></p>
<ul>
<li><p>参数规模降下来（358M）</p>
<p><img src="/image-20200409204836174.png" alt="image-20200409204836174" style="zoom:67%;" /></p>
</li>
</ul>
<h4 id="7-3-2-Inception-v2"><a href="#7-3-2-Inception-v2" class="headerlink" title="7.3.2 Inception-v2"></a>7.3.2 Inception-v2</h4><ul>
<li>加入BN<ul>
<li>网络训练变简单，收敛变快</li>
</ul>
</li>
<li>一个大的感受野用两个比较小的卷积核来近似<ul>
<li>参数规模进一步变小</li>
<li>网络深度进一步变深</li>
</ul>
</li>
</ul>
<p><img src="/image-20200409205108861.png" alt="image-20200409205108861" style="zoom:67%;" /></p>
<h4 id="7-3-3-Inception-v3"><a href="#7-3-3-Inception-v3" class="headerlink" title="7.3.3 Inception-v3"></a>7.3.3 Inception-v3</h4><ul>
<li><strong>Convolutional factorization卷积分解</strong>：将n×n矩阵分解成1×n和n×1矩阵相乘 （<strong>低秩近似</strong>low rank approximation：机器学习中用于降低模型大小或数据维度的常用思想）<ul>
<li>一个3×3的卷积核近似为两个1×3的卷积核，特征图尺度不会发生变化，但捕捉到的特征发生变化（对空间上不同位置的重要性的认知发生了变化，3×3中中间格子最重要，1×3中间第二个格子最重要）<ul>
<li>这个技术现在被人们用来做轻量化卷积网络</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/image-20200409205201873.png" alt="image-20200409205201873" style="zoom:67%;" /></p>
<h3 id="7-4-大道至简"><a href="#7-4-大道至简" class="headerlink" title="7.4 大道至简"></a>7.4 大道至简</h3><ul>
<li>ResNet证明可能还是简单的网络结构更好</li>
<li>是very deep NN的开端（<strong>残差连接机制有利于训练更深的网络</strong>）</li>
</ul>
<p><img src="/image-20200426131439768.png" alt="image-20200426131439768" style="zoom:67%;" /></p>
<h4 id="7-4-1-Highway-Networks（高速度网络）"><a href="#7-4-1-Highway-Networks（高速度网络）" class="headerlink" title="7.4.1 Highway Networks（高速度网络）"></a>7.4.1 Highway Networks（高速度网络）</h4><p>（very deep NN的真正开端，LSTM之父Jurgen Schmidhuber）</p>
<ul>
<li>普通前馈网络：利用上一层的特征x变换后得到下一层的特征y</li>
<li>highway network：认为经过变换后的上一层特征和不经过变换的上一层特征本身都会对下一层特征有贡献，即下一层特征应该由经过变换的特征和变换之前的特征做一个线性加权构成。<ul>
<li>权重由门结构控制，改变门来决定下一层特征更依赖上一层特征还是更依赖变换后的上一层特征。</li>
<li>这种思想最早来源于循环网络，Jurgen Schmidhuber想到这种结构并且把它用在卷积神经网络之中。</li>
<li><strong>可以让信息流在网络的所有层之间不受阻碍地传播，所以可以训练更深的网络</strong>。</li>
</ul>
</li>
</ul>
<p><img src="/image-20200426145052559.png" alt="image-20200426145052559" style="zoom:67%;" /></p>
<h4 id="7-4-2-Residual-Network（ResNet，残差网络）"><a href="#7-4-2-Residual-Network（ResNet，残差网络）" class="headerlink" title="7.4.2 Residual Network（ResNet，残差网络）"></a>7.4.2 Residual Network（ResNet，残差网络）</h4><p>（何恺明）</p>
<h5 id="7-4-2-1-ResNet"><a href="#7-4-2-1-ResNet" class="headerlink" title="7.4.2.1 ResNet"></a>7.4.2.1 ResNet</h5><p><strong>motivation：</strong></p>
<ul>
<li><p>56层网络堆叠在一起比20层的错误率反而更大</p>
</li>
<li><p>实验：训练好的20层网络的参数copy到56层的前20层，56层网络的后面用单位变换的层，这样的56层网络和20层网络应该是等价的。故任意其他56层的网络会包括前述的这样一个特殊的56层网络，其准确率应该和20层一样 。但事实上实验中56层的准确率下降。</p>
</li>
<li><p>观点：<strong>不是因为网络深带来过拟合，而是因为网络深不好优化</strong>。</p>
<p><img src="/image-20200426145920421.png" alt="image-20200426145920421" style="zoom:67%;" /></p>
</li>
<li><p><strong>用网络层拟合残差比拟合原函数更容易</strong>。</p>
</li>
</ul>
<p><strong>引用highway network得到残差模块：</strong></p>
<p>利用highway network可以让信息流（梯度）在网络的所有层之间不受阻碍地传播的能力，让两个门都是常数门，取值0.5，即输入特征和变换后的特征一样重要。 </p>
<p><img src="/image-20200426150616702.png" alt="image-20200426150616702" style="zoom:67%;" /></p>
<p><strong>大道至简：</strong></p>
<ul>
<li>堆叠残差模块</li>
<li>采用尽量简单的卷积核，用3×3</li>
<li>空间上不断double通道的个数，让网络抽取更多特征；同时用最简单的stride=2让特征图尺寸不断降低。</li>
<li>开始的地方加一些必要的卷积层做处理</li>
<li>最后一层做global average pooling将tensor池化成一个向量。即网络只有一个全连接层用来做分类。</li>
</ul>
<p><img src="/image-20200426151206475.png" alt="image-20200426151206475" style="zoom:67%;" /></p>
<p><img src="/image-20200426151320074.png" alt="image-20200426151320074" style="zoom:67%;" /></p>
<h5 id="7-4-2-2-improving-ResNet"><a href="#7-4-2-2-improving-ResNet" class="headerlink" title="7.4.2.2 improving ResNet"></a>7.4.2.2 improving ResNet</h5><p>（何恺明）res block怎样设计会更好？</p>
<ul>
<li>使用bottleneck layer（ 使用1*1的卷积神经网络，称之为瓶颈层 ） 方便改变维度，减少参数量</li>
<li>让直连更加直接：让直连发生在整个残差模块激活之后，之前在激活之前</li>
</ul>
<p><img src="/image-20200426153717579.png" alt="image-20200426153717579" style="zoom:67%;" /></p>
<h5 id="7-4-2-3-ResNeXt"><a href="#7-4-2-3-ResNeXt" class="headerlink" title="7.4.2.3 ResNeXt"></a>7.4.2.3 ResNeXt</h5><p>（Girshick R）</p>
<ul>
<li><p>让网络更宽（借鉴GoogleNet），多路网络捕捉更多特征</p>
<p><img src="/image-20200426153954178.png" alt="image-20200426153954178" style="zoom:67%;" /></p>
</li>
</ul>
<h5 id="7-4-2-4-DenseNet"><a href="#7-4-2-4-DenseNet" class="headerlink" title="7.4.2.4 DenseNet"></a>7.4.2.4 DenseNet</h5><ul>
<li>把直连做到极致，在任意两层之间都做直连<ul>
<li>底层特征可通过直连复用到高层</li>
</ul>
</li>
<li>参数爆炸：只在Dense block内部做直连，block之间不做。</li>
</ul>
<p><img src="/image-20200426154425125.png" alt="image-20200426154425125" style="zoom:67%;" /></p>
<h3 id="7-5-比较"><a href="#7-5-比较" class="headerlink" title="7.5 比较"></a>7.5 比较</h3><ul>
<li>希望准确率高、计算量小、模型内存占用低<ul>
<li>ResNet：强调准确率</li>
<li>Inception：参数量较小，强调速度</li>
</ul>
</li>
</ul>
<p><img src="/image-20200426154606077.png" alt="image-20200426154606077"></p>
<ul>
<li>更关心推理阶段的资源占用</li>
</ul>
<p><img src="/image-20200426154907835.png" alt="image-20200426154907835"></p>
<ul>
<li>参数效率：引入参数对准确率提高的贡献率<ul>
<li>Big model的参数效率是比较低的</li>
<li>反倒早期GoogleNet的参数效率比较高</li>
</ul>
</li>
</ul>
<p><img src="/image-20200426155100505.png" alt="image-20200426155100505"></p>
<h2 id="8-轻量化架构Lightweight-Architectures"><a href="#8-轻量化架构Lightweight-Architectures" class="headerlink" title="8 轻量化架构Lightweight Architectures"></a>8 轻量化架构Lightweight Architectures</h2><ul>
<li>大模型参数效率低，所以希望用更少的参数也可以达到更好的准确率。</li>
<li></li>
</ul>
<h2 id="9-进阶版Advanced-CNN-Modules"><a href="#9-进阶版Advanced-CNN-Modules" class="headerlink" title="9 进阶版Advanced CNN Modules"></a>9 进阶版Advanced CNN Modules</h2><h3 id="9-1-Transpose-Convolution"><a href="#9-1-Transpose-Convolution" class="headerlink" title="9.1 Transpose Convolution"></a>9.1 Transpose Convolution</h3><h3 id="9-2-3D-Convolution"><a href="#9-2-3D-Convolution" class="headerlink" title="9.2 3D Convolution"></a>9.2 3D Convolution</h3><h3 id="9-3-Graph-Convolution"><a href="#9-3-Graph-Convolution" class="headerlink" title="9.3 Graph Convolution"></a>9.3 Graph Convolution</h3><h3 id="9-4-Non-Local-Connection"><a href="#9-4-Non-Local-Connection" class="headerlink" title="9.4 Non-Local Connection"></a>9.4 Non-Local Connection</h3><h2 id="10-表示学习Representation-Learning"><a href="#10-表示学习Representation-Learning" class="headerlink" title="10 表示学习Representation Learning"></a>10 表示学习Representation Learning</h2><h2 id="11-自动化机器学习之神经架构搜索AutoML-Neural-Architecture-Search"><a href="#11-自动化机器学习之神经架构搜索AutoML-Neural-Architecture-Search" class="headerlink" title="11 自动化机器学习之神经架构搜索AutoML: Neural Architecture Search"></a>11 自动化机器学习之神经架构搜索AutoML: Neural Architecture Search</h2>
      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    Jingge
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="http://yoursite.com/2020/03/11/machine-learning/" title="machine learning">http://yoursite.com/2020/03/11/machine-learning/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tags"></i> Machine Learning</a>
          
            
            <a href="/tags/notes/" rel="tag"><i class="fa fa-tags"></i> notes</a>
          
            
            <a href="/tags/%E6%A0%A1%E5%86%85%E5%85%AC%E5%BC%80%E8%AF%BE/" rel="tag"><i class="fa fa-tags"></i> 校内公开课</a>
          
            
            <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tags"></i> Deep Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/07/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E4%B8%8ER%E8%AF%AD%E8%A8%80/" rel="next" title="数理统计与R语言">
                <i class="fa fa-chevron-left"></i> 数理统计与R语言
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/04/17/pieces/" rel="prev" title="pieces">
                pieces <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Jingge</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#校内深度学习公开课"><span class="nav-text">校内深度学习公开课</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-introduction"><span class="nav-text">1 introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#正则项-惩罚项"><span class="nav-text">正则项&#x2F;惩罚项</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#loss-function损失函数"><span class="nav-text">loss function损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三种regression"><span class="nav-text">三种regression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#linear-regression线性回归"><span class="nav-text">linear regression线性回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#logistic-regression逻辑回归"><span class="nav-text">logistic regression逻辑回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmax-regression"><span class="nav-text">Softmax regression</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#误差"><span class="nav-text">误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数化与非参数化"><span class="nav-text">参数化与非参数化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#维度灾难与流形学习"><span class="nav-text">维度灾难与流形学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#偏差与方差"><span class="nav-text">偏差与方差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#泛化"><span class="nav-text">泛化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型选择"><span class="nav-text">模型选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-感知机与多层感知机"><span class="nav-text">2 感知机与多层感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#单层感知机"><span class="nav-text">单层感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#收敛性"><span class="nav-text">收敛性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MLP-Multilayer-Perceptrons-多层感知机（MLP，Multilayer-Perceptrons）-全连接网络（Fully-connected-network）"><span class="nav-text">MLP(Multilayer Perceptrons) 多层感知机（MLP，Multilayer Perceptrons）&#x2F;全连接网络（Fully-connected network）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#从单层到多层感知机"><span class="nav-text">从单层到多层感知机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#激活函数-Activation-Functions"><span class="nav-text">激活函数 Activation Functions</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#隐藏层激活函数"><span class="nav-text">隐藏层激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#最常用的非线性激活函数：sigmoid"><span class="nav-text">最常用的非线性激活函数：sigmoid</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#其他激活函数"><span class="nav-text">其他激活函数</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#输出层激活函数：Softmax"><span class="nav-text">输出层激活函数：Softmax</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cost-function代价函数"><span class="nav-text">Cost function代价函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-反向传播-Back-propagation"><span class="nav-text">3 反向传播 Back propagation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#step1-前向传播：内存占用"><span class="nav-text">step1: 前向传播：内存占用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#step2-反向传播"><span class="nav-text">step2:反向传播</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#反向传播算法（BP）"><span class="nav-text">反向传播算法（BP）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算梯度"><span class="nav-text">计算梯度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#step3-更新参数（梯度下降GD）"><span class="nav-text">step3:更新参数（梯度下降GD）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自动求导Automatic-differentiation"><span class="nav-text">*自动求导Automatic differentiation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#比较不同微分方法"><span class="nav-text">比较不同微分方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#计算图"><span class="nav-text">计算图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#BP和自动求导比较"><span class="nav-text">BP和自动求导比较</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-训练技巧-Practical-training-strategies"><span class="nav-text">4 训练技巧 Practical training strategies</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#训练技巧"><span class="nav-text">训练技巧</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-梯度下降的进阶版本"><span class="nav-text">4.1 梯度下降的进阶版本</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-1-随机梯度下降（SGD，stochastic-gradient-descent）"><span class="nav-text">4.1.1 随机梯度下降（SGD，stochastic gradient descent）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-2-带冲量的SGD（SGD-with-Momentum）"><span class="nav-text">4.1.2 带冲量的SGD（SGD with Momentum）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-学习率衰减（Learning-Rate-Decay）"><span class="nav-text">4.2 学习率衰减（Learning Rate Decay）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-权重衰减（Weight-Decay）"><span class="nav-text">4.3 权重衰减（Weight Decay）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-Dropout"><span class="nav-text">4.4 Dropout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-权重初始化（Weight-initialization）"><span class="nav-text">4.5 权重初始化（Weight initialization）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6批量归一化（Batch-Normalization）"><span class="nav-text">4.6批量归一化（Batch Normalization）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6-1-motivation"><span class="nav-text">4.6.1 motivation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6-2-BN操作"><span class="nav-text">4.6.2 BN操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）训练阶段"><span class="nav-text">（1）训练阶段</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）测试阶段"><span class="nav-text">（2）测试阶段</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6-3-BN的作用"><span class="nav-text">4.6.3 BN的作用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6-4-进阶版BN"><span class="nav-text">4.6.4 进阶版BN</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-7-Babysitting-Learning"><span class="nav-text">4.7 Babysitting Learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-深度网络的表达能力Expressiveness-of-deep-networks"><span class="nav-text">5 深度网络的表达能力Expressiveness of deep networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#神经网络的深度depth"><span class="nav-text">神经网络的深度depth</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经网络的宽度width"><span class="nav-text">神经网络的宽度width</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经网络可以把空间切分成多少线性区域"><span class="nav-text">神经网络可以把空间切分成多少线性区域</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-卷积神经网络-Convolutional-neural-network"><span class="nav-text">6 卷积神经网络 Convolutional neural network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-CNN的提出"><span class="nav-text">6.1 CNN的提出</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-1-MLP存在的问题"><span class="nav-text">6.1.1 MLP存在的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-2-CNN的两个idea"><span class="nav-text">6.1.2 CNN的两个idea</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-CNN"><span class="nav-text">6.2 CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-1-卷积"><span class="nav-text">6.2.1 卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-2-互相关cross-correlation"><span class="nav-text">6.2.2 互相关cross-correlation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-3-卷积、互相关的关系"><span class="nav-text">6.2.3 卷积、互相关的关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-4-CNN"><span class="nav-text">6.2.4 CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-5-卷积的扩展"><span class="nav-text">6.2.5 卷积的扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）空洞卷积（Dilated-convolution）"><span class="nav-text">（1）空洞卷积（Dilated convolution）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）标准卷积、带步幅stride的卷积、空洞卷积"><span class="nav-text">（2）标准卷积、带步幅stride的卷积、空洞卷积</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-6-步幅和填充-（stride，-padding）"><span class="nav-text">6.2.6 步幅和填充 （stride， padding）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）步幅stride"><span class="nav-text">（1）步幅stride</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）填充padding"><span class="nav-text">（2）填充padding</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Summary：卷积操作特征图大小计算公式"><span class="nav-text">Summary：卷积操作特征图大小计算公式</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-7卷积层的超参数"><span class="nav-text">6.2.7卷积层的超参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-8-池化（Pooling）-下采样"><span class="nav-text">6.2.8 池化（Pooling）&#x2F; 下采样</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-9-卷积层、激活函数、池化层组成卷积网络"><span class="nav-text">6.2.9 卷积层、激活函数、池化层组成卷积网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）LeNet"><span class="nav-text">（1）LeNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）AlexNet"><span class="nav-text">（2）AlexNet</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-10-可视化特征图和卷积核"><span class="nav-text">6.2.10 可视化特征图和卷积核</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）可视化特征图"><span class="nav-text">（1）可视化特征图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）可视化滤波器-卷积核"><span class="nav-text">（2）可视化滤波器&#x2F;卷积核</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-反向传播算法BP（backpropagation）"><span class="nav-text">6.3 反向传播算法BP（backpropagation）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-1-前向传播"><span class="nav-text">6.3.1 前向传播</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-2-反向传播"><span class="nav-text">6.3.2 反向传播</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#池化层的bp计算"><span class="nav-text">池化层的bp计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#卷积层的bp计算"><span class="nav-text">卷积层的bp计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#梯度计算"><span class="nav-text">梯度计算</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-3-参数更新"><span class="nav-text">6.2.3 参数更新</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-卷积网络的实际训练技巧（Practical-training-strategies）"><span class="nav-text">6.4 卷积网络的实际训练技巧（Practical training strategies）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-1-Weight-initialization"><span class="nav-text">6.4.1 Weight initialization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-2-Batch-normalization"><span class="nav-text">6.4.2 Batch normalization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-不变性和等变性Invariance-vs-Equivariance"><span class="nav-text">6.5 不变性和等变性Invariance vs. Equivariance</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-0-不变性和等变性Invariance-vs-Equivariance"><span class="nav-text">6.5.0 不变性和等变性Invariance vs. Equivariance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-1-数据增广（Data-augmentation）"><span class="nav-text">6.5.1 数据增广（Data augmentation）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-2-平移不变性和等变性Rethinking-shift-invariance-and-equivariance"><span class="nav-text">6.5.2 平移不变性和等变性Rethinking shift invariance and equivariance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-3-Model-revolution-still-ongoing"><span class="nav-text">6.5.3 Model revolution: still ongoing</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-标准卷积神经网络架构Standard-Architectures"><span class="nav-text">7 标准卷积神经网络架构Standard Architectures</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-早期8层较浅深度网络"><span class="nav-text">7.1 早期8层较浅深度网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-1-AlexNet"><span class="nav-text">7.1.1 AlexNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-2-ZFNet"><span class="nav-text">7.1.2 ZFNet</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-较深、架构更复杂网络"><span class="nav-text">7.2 较深、架构更复杂网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-1-VGG"><span class="nav-text">7.2.1 VGG</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-2-网中网（Network-in-Network，NIN）"><span class="nav-text">7.2.2 网中网（Network in Network，NIN）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-魔改网络时代"><span class="nav-text">7.3 魔改网络时代</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-1-GoogLeNet（Inception-v1）"><span class="nav-text">7.3.1 GoogLeNet（Inception-v1）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#7-3-1-1-基本特点"><span class="nav-text">7.3.1.1 基本特点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-3-1-2-inception-module的发展过程"><span class="nav-text">7.3.1.2 inception module的发展过程</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-2-Inception-v2"><span class="nav-text">7.3.2 Inception-v2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-3-Inception-v3"><span class="nav-text">7.3.3 Inception-v3</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4-大道至简"><span class="nav-text">7.4 大道至简</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-1-Highway-Networks（高速度网络）"><span class="nav-text">7.4.1 Highway Networks（高速度网络）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-2-Residual-Network（ResNet，残差网络）"><span class="nav-text">7.4.2 Residual Network（ResNet，残差网络）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#7-4-2-1-ResNet"><span class="nav-text">7.4.2.1 ResNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-4-2-2-improving-ResNet"><span class="nav-text">7.4.2.2 improving ResNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-4-2-3-ResNeXt"><span class="nav-text">7.4.2.3 ResNeXt</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-4-2-4-DenseNet"><span class="nav-text">7.4.2.4 DenseNet</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-5-比较"><span class="nav-text">7.5 比较</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-轻量化架构Lightweight-Architectures"><span class="nav-text">8 轻量化架构Lightweight Architectures</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-进阶版Advanced-CNN-Modules"><span class="nav-text">9 进阶版Advanced CNN Modules</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-Transpose-Convolution"><span class="nav-text">9.1 Transpose Convolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-3D-Convolution"><span class="nav-text">9.2 3D Convolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3-Graph-Convolution"><span class="nav-text">9.3 Graph Convolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-4-Non-Local-Connection"><span class="nav-text">9.4 Non-Local Connection</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-表示学习Representation-Learning"><span class="nav-text">10 表示学习Representation Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-自动化机器学习之神经架构搜索AutoML-Neural-Architecture-Search"><span class="nav-text">11 自动化机器学习之神经架构搜索AutoML: Neural Architecture Search</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jingge</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count"></span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>


<script type="text/javascript">
    $('.post-body').bind('copy', function() {
        alert('本博客内容欢迎分享（将本博客的原文地址分享到其它网站），允许部分摘录并在醒目位置附上原文链接，未经许可禁止任何形式的全文转载。');
    });
</script>

  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
